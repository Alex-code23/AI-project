# CS 285 : Variational Inference & Generative Models (Lecture 18)

Ce document r√©sume le cours sur l'**Inf√©rence Variationnelle (VI)** et les **Mod√®les G√©n√©ratifs**.
L'objectif est d'apprendre des mod√®les probabilistes complexes $p_\theta(x)$ capables de g√©n√©rer des donn√©es (images, trajectoires) ou de repr√©senter des distributions multimodales, l√† o√π un simple r√©seau de neurones (MSE) √©chouerait √† capturer la diversit√©.

## üéØ Le Probl√®me : Mod√®les √† Variables Latentes

On suppose que nos donn√©es observables $x$ (ex: une image) sont g√©n√©r√©es par des variables cach√©es non-observ√©es $z$ (ex: "un chat", "position", "couleur").
Le mod√®le probabiliste joint est :
$$p_\theta(x, z) = p_\theta(x|z) p(z)$$
* $p(z)$ : Le prior sur les variables latentes (souvent $\mathcal{N}(0, I)$).
* $p_\theta(x|z)$ : La vraisemblance (le "D√©codeur"), souvent un r√©seau de neurones.

Pour entra√Æner ce mod√®le (trouver $\theta$), on veut maximiser la "log-vraisemblance marginale" des donn√©es :
$$\theta^* = \arg\max_\theta \sum_i \log p_\theta(x_i) = \arg\max_\theta \sum_i \log \int p_\theta(x_i|z) p(z) dz$$

**Probl√®me :** L'int√©grale $\int p_\theta(x|z) p(z) dz$ est **intractable** (impossible √† calculer analytiquement) pour des r√©seaux de neurones complexes. On ne peut donc pas optimiser directement cette fonction.

---

## üõ†Ô∏è L'Inf√©rence Variationnelle (Variational Inference)

Puisqu'on ne peut pas calculer $p(x)$, ni la vraie distribution *a posteriori* $p(z|x)$ (intractable aussi), on va l'**approximer**.
On introduit une distribution variationnelle $q_\phi(z|x)$ (l'"Encodeur") param√©tr√©e par $\phi$, et on essaie de la rendre aussi proche que possible du vrai posterior $p(z|x)$.

### La D√©rivation de l'ELBO
On utilise la divergence KL pour mesurer la distance entre notre approximation et la r√©alit√© :
$$D_{KL}(q_\phi(z|x) || p_\theta(z|x)) = E_{z \sim q} [\log q_\phi(z|x) - \log p_\theta(z|x)]$$

En r√©arrangeant les termes, on obtient l'identit√© fondamentale :
$$\log p_\theta(x) = D_{KL}(q_\phi(z|x) || p_\theta(z|x)) + \mathcal{L}(\theta, \phi)$$

O√π $\mathcal{L}$ est la **Borne Inf√©rieure de l'√âvidence (ELBO - Evidence Lower Bound)** :
$$\mathcal{L}(\theta, \phi) = E_{z \sim q_\phi(z|x)} [\log p_\theta(x|z)] - D_{KL}(q_\phi(z|x) || p(z))$$

* Puisque $D_{KL} \ge 0$, alors $\log p_\theta(x) \ge \mathcal{L}(\theta, \phi)$.
* Maximiser l'ELBO revient √† maximiser la vraisemblance des donn√©es **ET** minimiser l'√©cart entre notre approximation $q$ et le vrai posterior $p(z|x)$.

---

## ü§ñ Amortized Variational Inference & VAE

Au lieu d'optimiser une distribution $q_i$ diff√©rente pour chaque point de donn√©e $x_i$ (ce qui serait trop lent), on apprend un r√©seau de neurones **d'inf√©rence** $q_\phi(z|x)$ qui prend $x$ en entr√©e et pr√©dit les param√®tres de la distribution de $z$ (ex: moyenne $\mu$ et variance $\sigma^2$). C'est l'inf√©rence "amortie".

### Variational Auto-Encoder (VAE)
Le VAE est l'instanciation directe de ce principe avec des r√©seaux de neurones.

1.  **Encodeur ($q_\phi(z|x)$)** : Pr√©dit $\mu_\phi(x)$ et $\sigma_\phi(x)$.
2.  **D√©codeur ($p_\theta(x|z)$)** : Prend un $z$ √©chantillonn√© et reconstruit $x$.

**Fonction de Perte (Loss) = -ELBO :**
$$J(\theta, \phi) \approx \underbrace{- \log p_\theta(x|z)}_{\text{Reconstruction Loss}} + \underbrace{D_{KL}(q_\phi(z|x) || p(z))}_{\text{Regularization Loss}}$$

* **Reconstruction :** Le mod√®le doit bien compresser/d√©compresser l'image (MSE ou Cross-Entropy).
* **R√©gularisation :** L'espace latent doit ressembler au prior (Gaussienne standard). Cela force l'espace √† √™tre lisse et continu (bon pour la g√©n√©ration).

### Le "Reparameterization Trick"
Pour entra√Æner tout cela par descente de gradient, il faut pouvoir backpropager √† travers l'√©chantillonnage stochastique $z \sim q_\phi(z|x)$.
Si on √©chantillonne directement, le gradient est bloqu√©.
**Astuce :** On r√©√©crit le bruit al√©atoire comme une entr√©e externe.
$$z = \mu_\phi(x) + \sigma_\phi(x) \odot \epsilon, \quad \text{o√π } \epsilon \sim \mathcal{N}(0, I)$$
Maintenant, $z$ est une fonction d√©terministe et diff√©rentiable de $\phi$ et d'une constante $\epsilon$. Le gradient peut passer !

---

## üìà Liens avec le Reinforcement Learning

Pourquoi ce cours de VI en plein milieu du RL ?

1.  **Model-Based RL (Images) :** Comme vu au cours 12, les VAEs permettent d'apprendre des espaces d'√©tats latents compacts pour planifier √† partir d'images.
2.  **Exploration (Cours 14) :** VIME utilise l'inf√©rence variationnelle pour estimer le gain d'information sur la dynamique.
3.  **Politiques Stochastiques Optimales :** Le "Soft Optimality" framework (Soft Q-Learning, SAC) peut √™tre vu comme une forme d'inf√©rence variationnelle o√π on inf√®re la trajectoire optimale.
4.  **Offline RL (Cours 15) :** Les VAEs sont utilis√©s (ex: BCQ) pour mod√©liser la distribution des actions du dataset ($\pi_\beta$) et g√©n√©rer des actions valides.

---

## ‚úÖ R√©sum√© Technique

| Concept | Formule / D√©finition | R√¥le |
| :--- | :--- | :--- |
| **Latent Variable Model** | $p(x) = \int p(x|z)p(z)dz$ | Capturer la structure cach√©e et multimodale des donn√©es. |
| **ELBO** | $E_q[\log p(x|z)] - D_{KL}(q||p)$ | Borne inf√©rieure tractable de $\log p(x)$ qu'on maximise. |
| **Inference Network** | $q_\phi(z|x)$ | R√©seau (Encoder) qui approxime le vrai posterior $p(z|x)$. |
| **Reparameterization** | $z = \mu + \sigma \epsilon$ | Permet la backpropagation √† travers un n≈ìud stochastique. |

---
[cite_start]*Source: CS 285 Lecture 18 Slides, Instructor: Sergey Levine, UC Berkeley.* [cite: 1, 2, 4]